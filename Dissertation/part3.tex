\chapter{Разработка алгоритмической реализации метода прогнозирования временных рядов на основе нечетких моделей}\label{ch:ch3}


%\textbf{Третья глава} посвящена выработке эффективной параллельной реализации разработанного метода нечеткого вывода на основе нечеткого значения истинности с использованием технологии CUDA. В главе описан ключевые особенности организации вычисления нечеткого вывода при использовании технологии CUDA, параллельный алгоритм свертки НЗИ, особенности реализации методов дефаззификации в нечеткой модели регрессии и схема ускоренного вывода регрессионной нечеткой системы за счет предварительного отбора правил с ближайшими антецедентами.

\section{Параллельный алгоритм свертки НЗИ}


При программной реализации вычисления НЗИ и свертки НЗИ $\tau_{A_{ki}|A'_i}$ вычисление производится в точках расчетной сетки. \ul{Значение НЗИ по $i$-му входу в точке расчетной сетки $v_j$ в данной работе обозначается $ftv_i[v_j]$ (\textit{ftv --- fuzzy truth value}).} Расчетная сетка размера $D_{ftv}$ задается на пространстве $\mathbb{V}=[0;1]$ мощности $|\mathbb{V}|$.

Для нахождения свертки НЗИ по одному правилу можно составить параллельный алгоритм на основе формулы (\ref{eqn:ftv-compute-10}). Вычислительная сложность при параллельной реализации такого алгоритма составит $O\left(D_{ftv}^2 \cdot \log{n}\right)$. Значения $ftv_i[v_j]$ необходимо вычислить до запуска алгоритма свертки, что потребует сложности по памяти $O\left(D_{ftv}\cdot n\right)$. Кроме того параллельная свертка по формуле (\ref{eqn:ftv-compute-10}) потребует вычисления порядка $O(\log n)$ промежуточных попарных сверток в каждому входу. Узким местом в таком способе организации вычислений будет выступать ограниченность количества арифметико-логических модулей, между которыми распределяется работа в вычислительном устройстве.

В \cite{Karatach2024} разработан параллельный алгоритм для вычисления свертки НЗИ сразу по всем входам параллельно. Алгоритм опирается на допущение, что  $T_1 = min$, и имеет вычислительную сложность $O\left(D_{ftv}\cdot \log{n}\right)$.

\begin{algorithm}
	\begin{algorithmic}
		\Require $ftv_i,\ i=\overline{1,n}$ --- это $\tau_{A_{ki}|A'_i}$ дискретизированная в точках $v_j$
		\State $max\_ftv[i] = 0;$
		\For{$v_j = 1\dots0$}
		\State $s \gets \left\{ftv_i[v_j] \mid ftv_i[v_j] >= max\_ftv[i]\right\};$
		\State $max\_ftv[i] \gets max(max\_ftv[i], ftv_i[v_j]);$
		\State $v\_max\_index \gets \mathrm{arg\,max}_i\left\{ftv_i[v_j]\right\};$
		\If{$s = \emptyset \And i = v\_max\_index$}
		\State $r[i] \gets ftv_{i}[v_j];$
		\Else
		\State $r[i] \gets max\_ftv[i];$
		\EndIf
		\State $ftv\_reduced[v_j] \gets \underset{i}{T_3}\left\{r[i]\right\}$;
		\EndFor
		\State \Return $ftv\_reduced$
	\end{algorithmic}
	\caption{Алгоритм свертки НЗИ при $T_1=min$}
	\label{alg:ftv-reduction}
\end{algorithm}

Как проиллюстрировано на рисунке \cref{fig:ftvs-reduction-example}, данный алгоритм итеративно вычисляет значения $\tau_{\mathbf{A_k}|\mathbf{A'}}(v_j)$, продвигаясь от точки $v_j = 1$ к $v_j = 0$. На каждой $j$-й итерации вычисляются значения $ftv_i[v_j]$, которые агрегируются в одном вспомогательном массиве \textit{max\_ftv}, что требует сложности по памяти $O\left(n\right)$ и реализует технику динамического программирования, избавляя от необходимости поиска этих значений на каждой итерации.

Также, поскольку на $j$-й итерации значение $\tau_{\mathbf{A_k}|\mathbf{A'}}(v_j)$ выражается из значений НЗИ по входам в точках $v_{ki}, i=\overline{1,n}$, то, с учетом ограничения алгоритма $T_1 = min$ и согласно выражению из формулы (\ref{eqn:ftv-compute-8})
\[
\underset{i=\overline{1,n}}{\mathrm{T_1}}v_{ki} = v_j,
%\sup_{\substack{\underset{i=\overline{1,n}}{\mathrm{T_1}}v_i = v \\ (v_1, \dots, v_n) \in [0, 1]^n}} \left\{\underset{i=\overline{1,n}}{\mathrm{T_3}}\tau_{A_{ki}|A'_i}(v_i)\right\}
\]
для одного из значений $v_{ki}$ необходимо выполнение $V_{ki} = v_j$. Для этого в \cref{alg:ftv-reduction} используется максимальное значение $\tau_{A_{ki}|A'_i}(v_j), i=\overline{1,n}$, когда ни по одному входу не обнаружено нового максимума ф. п. НЗИ в точке $v_j$.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{ftvs-reduction-example-gradient}
	\caption{Пример работы параллельного алгоритма свертки НЗИ при расчетной сетке состоящей из 5 точек.}
	\label{fig:ftvs-reduction-example}
\end{figure}


%При дискретизированном вычисление ф. п. свертки НЗИ в некоторой точке расчетной сетки $v_j\in [0,1]$ потребуется просматривать значения НЗИ в отрезке $[v_j, 1]$, то есть имеет вычислительную сложность $O(D_{ftv})$, где $D_{ftv}$ --- число точек расчетной сетки ф. п. НЗИ. Таким образом вычисление свертки НЗИ по формуле (\ref{eqn:ftv-compute-11}) может быть распараллелено по точкам расчетной сетки, а нахождение $\tau_{\mathbf{A_k}|\mathbf{A'}}(v_j)$ использует операцию свертки, которая в имеет ограниченную возможность распараллеливания, но в целом требует большого количества повторных вычислений значений $\tau_{A_{ki}|A'_i}(v_k), v_k\in [v_j, 1]$. В \ref{alg:ftv-reduction} \cite{} предложен алгоритм вычисления свертки НЗИ сразу по всем входам с использованием техники динамического программирования, имеющий линейную зависимость от размера расчетной сетки $D_{ftv}$..


\section{Адаптация алгоритма PSO для построения базы правил.}

Для построения базы правил у популярных в литературе типов нечетких систем Мамдани и Такаги-Сугено широко применяется алгоритм формирования правил но из данных \cite{Wang1992}. В контексте задачи прогнозирования временных рядов широкое применение в публикациях получили различные методы, являющиеся развитием или продолжением данного алгоритма \cite{Chellai2022}.

В этих подходах нечеткие множества, задающие значения в правилах, интерпретируются как термы лингвистических переменных. В контексте временных рядов это означает, что область значений изменяющейся во времени величины разбивается на соседствующие отсчеты (интервалы), каждому из которых соответствует терм лингвистической переменной.

\begin{enumerate}
	\item Границы пространство значений временной последовательности $U = [D_{min} - \delta_1, D_{max} + \delta_2]$ задаются на основе минимального $D_{min}$ и максимального $D_{max}$ присутствующих в данных значений с некоторыми отступами $\delta_1$ и $\delta_2$ соответственно.
	\item Пространство $U$ разбивается на $m$ равных отсчетов $u_1, u_2, \dots, u_m$.
	\item Набор соответствующих отсчетам нечетких множеств формирует множество термов лингвистических переменных $y_t, t=\overline{1, T}$.
	\item Затем каждому измеренному значению ставится в соответствие терм лингвистической переменной с наибольшей степенью истинности. Из последовательностей таких термов формируется набор правил --- набор нечетких отношений.
\end{enumerate}

Очевидным недостатком такого примитивного способа разбиения пространства значений является несоответствие часто отличному от равномерного распределению функции плотности вероятности этих значений. База правил формировалась напрямую из экземпляров данных, посредством сопоставления каждому экземпляру комбинации термов, имеющих наибольшую степень принадлежности по входам в совокупности.

%Развитие способов обучения нечетких систем в рамках задачи прогнозирования временных рядов проходило взаимосвязано с адаптацией нечеткого моделирования как непосредственно к задаче регрессии временных рядов, так и к задачам моделирования другого рода. Ранние подходы следовали более типовому набору шагов при построении нечетких систем \cite{Chellai2022}. При формирования набора термов лингвистической переменной $\tilde{y}$ ее пространство значений ограничивалось минимальным и максимальными значениями временного ряда и разбивалось на накладывающиеся друг на друга участки, каждый из которых составлял носитель соответствующего нечеткого множества из набора термов. В широко цитируемом подходе Chen-а \cite{Chen1996} разбиение производилось на равные отрезки. Очевидным недостатком такого примитивного способа разбиения пространства значений является несоответствие часто отличному от равномерного распределению функции плотности вероятности этих значений. База правил формировалась напрямую из экземпляров данных, посредством сопоставления каждому экземпляру комбинации термов, имеющих наибольшую степень принадлежности по входам в совокупности, что соответствует довольно популярному из-за своей простоты методу Wang-а \cite{Wang1992}. Такой способ построения базы правил нечеткой системы до сих пор популярен при исследовании нечетких моделей временных рядов и других данных, когда необходимо сравнить качество непосредственно моделирования при том же наборе данных и способе построения базы правил.

%В более поздних способах стало более распространенным формирование базы правил с соответствующими терм-множествами из данных, то есть подбор параметров функций принадлежности термов выполняется одновременно с формированием набора правил. Этот подходя является более простым и точным для выделение шаблонных отрезков из временных рядов, особенно в случаях сложной функции плотности распределения значений временного ряда, когда проявляются ограничения в увеличении точности нечеткой системы при разбиения базового множества лингвистической переменной $\tilde{y}$. Таким образом одни и те же методы можно применять для разбиения пространства значений временных рядов (одно измерение) или для разделения пространства окон временных рядов (когда последовательность значений в окне временного ряда интерпретируется как точка в $n$-мерном пространстве). В последнем случае посредством разбиения пространства окон временного ряда может осуществляться формирование базы правил.

%Распространенной группой таких методов являются подходы на основе различных алгоритмов кластеризации \cite{Lucas2021}:  \textit{k}-средних, алгоритмы учитывающие плотность распределения точек, агломеративная кластеризация.

%Эволюционные подходы, например, Particle Swarm Optimization (PSO)\cite{Davari2009} могут обеспечить оптимальную настройку параметров нечеткой модели при сложной конфигурации обучающего набора данных. 

%Основная сложность использования этих методов состоит в необходимости выполнять большое количество вычислений функции приспособленности на всем обучающем наборе данных на каждой итерации для всех особей популяции. Поэтому для сокращения времени оценки параметров модели стараются минимизировать набор параметров, для которых применяются методы глобальной оптимизации.

Чаще используются подходы построения базы правил, где значения термов в каждом правиле являются индивидуальным, то есть подбираются параметры нечетких множеств в правилах с уходом от лингвистической интерпретации.

Тогда каждое такое нечеткое множество в каждом правиле будет определяться индивидуальными значениями параметров функции принадлежности, а для задания всей базы правил требуется задание матрицы параметров $\theta_{\mathbf{R}}$

\begin{equation*}
	\theta_{\mathbf{R}} = \begin{bmatrix}
		\theta_{\mu_{\mathbf{R_1}}}\\
		\vdots\\
		\theta_{\mu_{\mathbf{R_N}}}
	\end{bmatrix} = \begin{bmatrix}
		\theta_{\mu_{A_{11}}} & \theta_{\mu_{A_{12}}} & \dots & \theta_{\mu_{A_{1n}}} & \theta_{\mu_{B_{1}}} \\
		\vdots & \vdots & \ddots & \vdots & \vdots \\
		\theta_{\mu_{A_{N1}}} & \theta_{\mu_{A_{N2}}} & \dots & \theta_{\mu_{A_{Nn}}} & \theta_{\mu_{B_{N}}} \\
	\end{bmatrix}.
\end{equation*}

При использовании гауссовых функций принадлежности c параметрами $a$ и $b$ для нечетких множеств в правилах матрица параметров может быть записана следующим образом:

\begin{equation*}
	\theta_{\mathbf{R}} = \begin{bmatrix}
		\langle a_{\mu_{A_{11}}}, b_{\mu_{A_{11}}}\rangle & \langle a_{\mu_{A_{12}}}, b_{\mu_{A_{12}}}\rangle & \dots & \langle a_{\mu_{A_{1n}}}, b_{\mu_{A_{1n}}}\rangle & \langle a_{\mu_{B_{1}}}, b_{\mu_{B_{1}}}\rangle \\
		\vdots & \vdots & \ddots & \vdots & \vdots \\
		\langle a_{\mu_{A_{N1}}}, b_{\mu_{A_{N1}}}\rangle & \langle a_{\mu_{A_{N2}}}, b_{\mu_{A_{N2}}}\rangle & \dots & \langle a_{\mu_{A_{Nn}}}, b_{\mu_{A_{Nn}}}\rangle & \langle a_{\mu_{B_{N}}}, b_{\mu_{B_{N}}}\rangle \\
	\end{bmatrix}.
\end{equation*}

Для подбора параметров функций принадлежности в наборе правил используется оптимизация этих параметров на основе набора данных, а критерием оптимизации является минимизация метрики среднеквадратичной ошибки (RMAE - Root Mean Square Error). В качестве такого алгоритма выбран \textit{метод роя частиц (Particle Swarm Optimization - PSO)}, который приведен на рисунке Алгоритм \ref{alg:pso}. Частицы в PSO используют как собственный опыт, так и опыт соседей, сглаживая свою траекторию за счет использования промежуточного вектора скорости для каждой точки, дающего эффект инерции. Это позволяет алгоритму избегать застревания в локальных минимумах. В контексте оптимизации вектора параметров функций принадлежности базы правил большой размерности (часто, сотни параметров), PSO хорошо выполняет оптимизацию по всем размерностям одновременно. При работе алгоритм сперва исследует широкое пространство решений, а затем сосредоточиться на его уточнении, что также позволяет бороться с попаданием в локальный оптимум. Основные параметры --- количество частиц $S$, вес инерции $\omega$ и коэффициенты влияния текущего локального $\phi_l$ и глобального $\phi_g$ оптимума.

Для построения базы правил $\mathbf{R}$ на основе набора данных сперва данные были представлены в виде входных нечетких множеств посредством фаззификации. Затем выполнялась оптимизация матрицы параметров ф. п. нечетких множеств базы правил $\theta_{\mathbf{R}}$:

\begin{equation*}
	\theta_{\mathbf{R}} = \begin{bmatrix}
		\theta_{\mu_{\mathbf{R_1}}}\\
		\vdots\\
		\theta_{\mu_{\mathbf{R_N}}}
	\end{bmatrix} = \begin{bmatrix}
		\theta_{\mu_{A_{11}}} & \theta_{\mu_{A_{12}}} & \dots & \theta_{\mu_{A_{1n}}} & \theta_{\mu_{B_{1}}} \\
		\vdots & \vdots & \ddots & \vdots & \vdots \\
		\theta_{\mu_{A_{N1}}} & \theta_{\mu_{A_{N2}}} & \dots & \theta_{\mu_{A_{Nn}}} & \theta_{\mu_{B_{N}}} \\
	\end{bmatrix}.
\end{equation*}

В качестве функций принадлежностей в работе используются гауссовы функции, которые задаются набором параметров:
\begin{equation*}
	\theta_{\mu_{A_{ki}}} = \langle a_{\mu_{A_{ki}}}, b_{\mu_{A_{ki}}}\rangle,\quad\theta_{\mu_{B_{k}}} = \langle a_{\mu_{B_{k}}}, b_{\mu_{B_{k}}}\rangle,
\end{equation*}

где $a$ и $b$ --- математическое ожидание и среднеквадратичное отклонение гауссовой функции принадлежности.

Подбор параметров для фиксированного количества правил и заданной метрики осуществлялся с использованием адаптированного алгоритма оптимизации метод роя частиц (Particle Swarm Optimization, PSO), который приведен в алгоритме \ref{alg:pso}.

\begin{algorithm}[p]
	\caption{Particle Swarm Optimization (PSO) для подбора параметров ф. п. в правилах на основе эталонных данных}
	\label{alg:pso}
	\begin{algorithmic}[1]
		\Require
		\Statex $S$ --- количество частиц
		\Statex $max\_iter$ --- количество итераций
		\Statex $\omega$ --- вес инерции
		\Statex $\phi_l, \phi_g$ --- коэффициенты влияния локального и глобального оптимума
		\Statex $b_{lo}, b_{up}$ --- вектора нижних и верхних граничных значений вектора параметров частицы $\theta_p$
		\Statex $D_{l=1}^M$ --- набор эталонных данных
		\Statex $f(\theta)$ --- целевая функция приспособленности для набора данных $D$
		
		\Statex \textbf{Инициализация:}
		\For{каждой частицы $p = 1, \dots, S$}
		\State Инициализировать позицию частицы по равномерному распределению: $\theta_p \sim U(b_{lo}, b_{up})$
		\State Установить $\theta^l_p \gets \theta_p$ \Comment{Локальный оптимум частицы}
		\State Инициализировать скорость по равномерному распределению: $v_p \sim U(-|b_{up}-b_{lo}|, |b_{up}-b_{lo}|)$ \Comment{Вектор скорости $v_p$ имеет такую же размерность как и вектор параметров $\theta_p$}
		\EndFor		
		\State $\theta^g \gets \argmin_{p} f(\theta^l_p)$ \Comment{Инициализация глобального оптимума}
		
		\Statex \textbf{Основной цикл:}
		\For{$i = 1, \dots, max\_iter$}
		\For{каждой частицы $p = 1, \dots, S$}
		\State Сгенерировать случайные $r_l, r_g \sim U(0,1)$
		\State Обновить скорость:
		\State \quad $v_p \gets \omega v_p + \phi_l r_l (\theta^l_p - \theta_p) + \phi_g r_g (\theta^g - \theta_p)$
		\State Обновить позицию:  $\theta_p \gets \theta_p + v_p$
		\If{$f(\theta_p) < f(\theta^l_p)$}
		\State Обновить локальный оптимум: $\theta^l_p \gets \theta_p$
		\If{$f(\theta^l_p) < f(\theta^g)$}
		\State Обновить глобальный оптимум: $\theta^g \gets \theta^l_p$
		\EndIf
		\EndIf
		\EndFor
		\EndFor
		
		\State \textbf{Возврат} $\theta^g$ \Comment{Найденный глобальный оптимум}
	\end{algorithmic}
\end{algorithm}

Минимально необходимый объем данных в наборе для обучения обычно оценивается формулой:
\[
C \times N \times n \times <\textit{количество параметров ф. п.}>,
\]
где $C$ --- коэффициент, зависящий от однородности распределения измеренных значений временного ряда и сложности закономерностей в исходных временных рядах.

\section{Применение алгоритма оптимизации на основе метода роя частиц для вычисления дефаззификации по среднему максимуму}

Производительность дефаззификации по \textit{упрощенной схеме метода COG} может быть увеличена путем масштабирования вычислений внутри блока по центрам выходной лингвистической переменной.

Поскольку используемые в данной работе в качестве функций принадлежности гауссовы функции являются гладкими во всей области определения выходной лингвистической переменной, для точного нахождения максимального значения ф. п. выходного нечеткого множества при дефаззификации по \textit{методу среднего максимума (MeOM)} можно использовать алгоритм градиентного спуска. В ситуации когда вычисление значения агрегированной по всем правилам выходной функции принадлежности и ее производных в некоторой точке выходного пространства является вычислительно сложной процедурой, целесообразно будет использовать \textit{метод Ньютона второго порядка} для более быстрого нахождения точки максимума выходной ф. п.:
\begin{equation}
	y^{(k+1)} = y^{(k)} - \alpha \frac{\mu_{B'}^{'}(y^{(k)})}{\mu_{B'}^{''}(y^{(k)})},
	\label{eqn:defuz-impl-meom-1}
\end{equation}
где $\alpha $ - коэффициент шага градиента.

Сложность может составить вопрос инициализации начальной координаты точки $y^{(0)}$, ведь в отдаленных от точки максимума выходной ф. п. $\mu_{B'}(y^{(0)})$  соответствующая ее минимуму гауссова функция может принять горизонтальный вид с нулевыми производными вне границ отрезка $[a_{B'} - 4 b_{B'}, a_{B'} + 4 b_{B'}]$. Для получения начального приближения можно использовать вычислительно более простой метод дефаззификации, например, дефаззификацию по методу среднего центра (CA). Также стоит добавить в формулу (\ref{eqn:defuz-impl-meom-1}) штраф за отдаление от точки $\hat{y}_{CA}$ с весовым параметром учета штрафа $\lambda$, а также учитывать штраф при низких значениях $\mu_{B'}(y^{(k)})$. С помощью параметра $\lambda$ и номера итерации $k$ можно обеспечить плавный сдвиг вклада в шаг итерации от штрафа до значения градиента с ростом числа прошедших итераций. Тогда формула (\ref{eqn:defuz-impl-meom-1}) примет вид:
\begin{gather*}
	y^{(k+1)} = y^{(k)} + \alpha \left(\mu_{B'}(y^{(k)})(1-\lambda)\left(-\frac{\mu_{B'}^{'}(y^{(k)})}{\mu_{B'}^{''}(y^{(k)})}\right) + (1-\mu_{B'}(y^{(k)}))\lambda (\hat{y}_{CA} - y^{(k)})\right),\\
	\lambda = e^{-k \gamma},
	\label{eqn:defuz-impl-meom-2}
\end{gather*}
где хорошая сходимость алгоритма показывается при выборе для параметра $\gamma$ значения равного коэффициенту шага $\alpha$.

Для преодоления проблемы локальных максимумов выходной функции принадлежности (которые ожидаемо возникнут при использовании $t$-нормы минимума или произведения для агрегации гауссовых функций) и сглаживания линии градиента, распространенной практикой является добавление момента $v^(k)$ в алгоритм градиентного спуска:
\begin{gather}
	\begin{split}
		v^{(k+1)} = \omega v^{(k)} + (\mu_{B'}(y^{(k)})(1-\lambda)\left(-\frac{\mu_{B'}^{'}(y^{(k)})}{\mu_{B'}^{''}(y^{(k)})}\right) + (1-\mu_{B'}(y^{(k)}))\lambda (\hat{y}_{CA} - y^{(k)})),\\
		y^{(k+1)} = y^{(k)} + \alpha v^{(k+1)},
	\end{split}
	\label{eqn:defuz-impl-meom-3}
\end{gather}
где $\omega$ --- параметр скользящего среднего значения момента.

\begin{figure}[ht]
	\centering
	\includegraphics{meom-use-case.png}
	\caption{Ситуация необходимости нахождения среднего максимума при дефаззификации агрегированной функции принадлежности $\mu_{B'}(y)$.}
	\label{fig:defuz-meom-use-case}	
\end{figure}

Необходимость усреднения максимумов при использовании метода дефаззификации Mean of Maximum возникает в ситуации изображенной на рисунке \cref{fig:defuz-meom-use-case}, где истинное значение $y$ нарисовано пунктирной линией. Вычислить среднее значение $y$ можно как выборочное среднее. Получить такую выборку точек можно посредством многократной оптимизации описанном выше методом. Как и в случае с упрощенной схемой дефаззификации каждая такая оптимизация может происходить в отдельной группе нитей (warps) за счет масштабирования одного CUDA-блока.

Для этого можно использовать один из методов глобальной оптимизации, например, \textit{Gradient-aware Particle Swarm Optimization}. Метод Particle Swarm Optimization (PSO) обеспечивает синхронизацию информации о текущей глобальной точке оптимума на данной итерации внутри популяции точек, что сокращает число итерации до сходимости к максимальному значению выходной функции принадлежности. С учетом (\ref{eqn:defuz-impl-meom-3}) для данного метода формулы шага оптимизации можно составить следующим образом:
\begin{align}
	\begin{split}
		v_i^{(k+1)} &= \omega v_i^{(k)} +\\
		&+ \alpha_l \left(
		r_l\left(
		y_i^{best} - y_i^{(k)}
		\right) + (1-r_l)\left(
		-\frac{\mu_{B'}^{'}(y_i^{(k)})}{\mu_{B'}^{''}(y_i^{(k)})}
		\right)
		\right) + \\
		&+ \alpha_g \left(
		r_g \mu_{B'}(y^{best})\left(
		y^{best}-y
		\right) + (1-r_g) \left(
		1-\mu_{B'}(y^{best})
		\right) \left(
		\hat{y}_{CA} - y^{(k)}
		\right)
		\right), \label{eqn:defuz-impl-meom-4-1}
	\end{split}\\
	y^{(k+1)} &= y^{(k)} + v^{(k+1)}, \nonumber
\end{align}
где $\alpha_l$ и $\alpha_g$ --- коэффициенты шага в направлении текущей точки локального и глобального оптимума, $r_l$ и $r_g$ --- случайно сгенерированные числа в диапазоне $[0,1]$, параметризующие движение в сторону текущих точек локального и глобального оптимума алгоритма PSO между движением в сторону роста градиента и точки начального приближения $\hat{y}_{CA}$ соответственно.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.55]{defuz-meom-pos-hue.png}
	%	\hfill
	%	\begin{subfigure}{0.5\textwidth}
		%		\centering
		%		\includegraphics{defuz-meom-pos-brightness.png}
		%	\end{subfigure}
	\caption{Динамика движения точек популяции при работе алгоритма глобальной оптимизации Gradient-aware PSO.}
	\label{fig:defuz-meom-pso-hue}
\end{figure}

Компонента после коэффициента $\alpha_l$ в формуле (\ref{eqn:defuz-impl-meom-4-1}) обеспечить разнообразие среди точек популяции, достигших максимума $\mu_{B'}(y_i^{(k)})$. График работы такого алгоритма PSO приведен на рисунке \cref{fig:defuz-meom-pso-hue}. Как видно из него --- большинство точек популяции сосредоточились возле точки оптимума.

Для реализации дефаззификации по \textit{методу центра тяжести} можно использовать алгоритм оптимизации из предыдущего метода, сохраняя координаты $y_i^{(k)}$ и значения $\mu_{B'}(y_i^{(k)})$ на каждой итерации, а затем для вычисления формулы (\ref{eqn:defuz-cog-1}) использовать численное интегрирование, например, методом Симпсона.

\section{Процедура метода прогнозирования временных рядов на основе разработанной нечеткой модели}

Разработанный метод прогнозирования временных рядов на основе нечеткой модели включает две основные процедуры: построение базы правил (обучение модели) и прогнозирование будущих значений временного ряда. Обе процедуры опираются на единую схему предварительной обработки входных данных и нечеткого вывода, но отличаются целями и используемыми алгоритмами оптимизации.

Процедура построения базы правил начинается с подготовки обучающего набора данных путем нарезания временного ряда на перекрывающиеся окна размером $p$, где $p$ --- параметр запаздывания, определяющий количество входов нечеткой модели. Каждое окно представляет собой вектор из $p$ последовательных значений, которые служат входами в нечеткую модель, а целевым значением является следующее значение временного ряда. На этапе адаптивной фаззификации каждое окно преобразуется в набор входных нечетких множеств, которые отражают степень принадлежности значений окна к различным нечетким множествам. Адаптивность фаззификации заключается в автоматической подстройке параметров функций принадлежности в соответствии с распределением данных. Затем выполняется оптимизация параметров базы правил с использованием алгоритма метода роя частиц (PSO), который минимизирует выбранную целевую метрику (MAE, MAPE, sMAPE, MSE или RMSE) на обучающем наборе данных. Процесс оптимизации включает вычисление нечеткого вывода для каждого фаззифицированного окна, агрегирование результатов по правилам базы и дефаззификацию с использованием адаптированного алгоритма Gradient-aware PSO для методов дефаззификации, требующих поиска экстремумов.

\begin{algorithm}[h]
	\caption{Построение базы правил нечеткой модели для прогнозирования временных рядов}
	\label{alg:fuzzy-ts-training}
	\begin{algorithmic}[1]
		\Require
		\Statex $X_{train}$ --- обучающий набор временных рядов
		\Statex $p$ --- размер окна запаздывания (количество входов)
		\Statex $N$ --- количество правил в базе правил
		\Statex $target\_metric$ --- целевая метрика оптимизации (MAE, MAPE, sMAPE, MSE, RMSE)
		\Statex $impl\_type$ --- тип импликации (Лукасевича, Рейхенбаха, Ягера, Клини-Динса)
		\Statex $rules\_pso\_sz$ --- количество частиц в PSO для оптимизации базы правил
		\Statex $rules\_pso\_cnt$ --- количество итераций алгоритма PSO для оптимизации базы правил
		\Statex $defuz\_pso\_sz$ --- количество частиц в Gradient-aware PSO для дефаззификации
		\Statex $defuz\_pso\_cnt$ --- количество итераций Gradient-aware PSO для дефаззификации
		
		\State $\{X'_{train}\}^{M'_{train}}_{l=1} \gets \mathrm{SlidingWindow}(X_{train}, p)$ \Comment{Нарезание на окна запаздывания}
		
		\State $\{\mathbf{A'}_{train}\}^{M'_{train}}_{l=1} \gets \mathrm{AdaptiveFuzzification}(\{X'_{train}\}^{M'_{train}}_{l=1})$ \Comment{Адаптивная фаззификация входов}
		
		\State $\{y_{train}\}^{M'_{train}}_{l=1} \gets \mathrm{ExtractTargets}(X_{train}, p)$ \Comment{Извлечение целевых значений}
		
		\State $\mathbf{R} \gets \mathrm{OptimizeRuleBase}(\{\mathbf{A'}_{train}\}^{M'_{train}}_{l=1}, \{y_{train}\}^{M'_{train}}_{l=1}, N,$ \Comment{Оптимизация параметров базы правил}
		\Statex \quad $target\_metric, impl\_type, rules\_pso\_sz, rules\_pso\_cnt, defuz\_pso\_sz, defuz\_pso\_cnt)$
		
		\State \textbf{Возврат} $\mathbf{R}$ \Comment{Построенная база правил}
	\end{algorithmic}
\end{algorithm}

Процедура прогнозирования временных рядов с использованием построенной базы правил структурно подобна процедуре обучения на этапах подготовки данных, но вместо оптимизации параметров выполняется пакетное вычисление прогнозных значений. На входе процедура получает временной ряд для прогноза, построенную базу правил и те же параметры фаззификации, которые использовались при обучении. Нарезание временного ряда на окна осуществляется с тем же размером запаздывания $p$, что обеспечивает согласованность между этапом обучения и прогнозирования. Адаптивная фаззификация применяется к входным окнам, преобразуя их в нечеткие множества, которые интерпретируются моделью. Затем для каждого фаззифицированного окна выполняется нечеткий вывод с использованием построенной базы правил, что приводит к вычислению агрегированной выходной функции принадлежности. Дефаззификация этой функции с помощью адаптированного алгоритма Gradient-aware PSO преобразует нечеткий результат в четкое числовое значение прогноза.

\begin{algorithm}[h]
	\caption{Прогнозирование временного ряда на основе построенной базы правил}
	\label{alg:fuzzy-ts-forecasting}
	\begin{algorithmic}[1]
		\Require
		\Statex $X$ --- временной ряд для прогноза
		\Statex $\mathbf{R}$ --- построенная база правил
		\Statex $p$ --- размер окна запаздывания (количество входов)
		\Statex $impl\_type$ --- тип импликации (Лукасевича, Рейхенбаха, Ягера, Клини-Динса)
		\Statex $defuz\_pso\_sz$ --- количество частиц в Gradient-aware PSO для дефаззификации
		\Statex $defuz\_pso\_cnt$ --- количество итераций Gradient-aware PSO для дефаззификации
		
		\State $\{X'\}^{M'}_{l=1} \gets \mathrm{SlidingWindow}(X, p)$ \Comment{Нарезание на окна запаздывания}
		
		\State $\{\mathbf{A'}\}^{M'}_{l=1} \gets \mathrm{AdaptiveFuzzification}(\{X'\}^{M'}_{l=1})$ \Comment{Адаптивная фаззификация входов}
		
		\State $\{\hat{y}\}^{M'}_{l=1} \gets \mathrm{FuzzyInferenceBatch}(\{\mathbf{A'}\}^{M'}_{l=1}, \mathbf{R},$ \Comment{Пакетный нечеткий вывод}
		\Statex \quad $impl\_type, defuz\_pso\_sz, defuz\_pso\_cnt)$
		
		\State \textbf{Возврат} $\{\hat{y}\}^{M'}_{l=1}$ \Comment{Прогнозные значения}
	\end{algorithmic}
\end{algorithm}

Ключевой связью между двумя процедурами является адаптивная фаззификация, параметры которой должны быть согласованы между этапами обучения и прогнозирования. На этапе обучения параметры фаззификации адаптируются на основе статистических свойств обучающего набора данных (математическое ожидание, дисперсия, минимальное и максимальное значения), и эти же параметры впоследствии применяются при фаззификации входных окон для прогнозирования без каких-либо изменений. Это обеспечивает корректную интерпретацию входных данных нечеткой моделью и согласованность между фазами обучения и применения.

Алгоритм OptimizeRuleBase в процедуре построения базы правил осуществляет итеративный поиск оптимальных параметров функций принадлежности нечетких множеств в правилах, минимизируя выбранную метрику на обучающем наборе. Количество правил $N$ фиксируется заранее и определяет структуру базы правил. Для каждого набора параметров, генерируемых алгоритмом PSO, вычисляется нечеткий вывод с использованием выбранного типа импликации для всех обучающих примеров, что требует дефаззификации промежуточных результатов с использованием Gradient-aware PSO. Оптимизируемые параметры включают центры и ширины гауссовых функций принадлежности для каждого входа и выхода каждого правила, образуя матрицу $\theta_{\mathbf{R}}$, размерность которой зависит от количества правил $N$, количества входов $p$ и выбранной параметризации функций принадлежности.

Алгоритм FuzzyInferenceBatch в процедуре прогнозирования применяет уже оптимизированную базу правил $\mathbf{R}$ ко всем входным окнам прогнозируемого временного ряда, производя массивно-параллельные вычисления нечеткого вывода с использованием технологии CUDA. Параллельный алгоритм свертки НЗИ, описанный в предыдущем разделе, обеспечивает эффективное агрегирование результатов правил с вычислительной сложностью $O(D_{ftv} \cdot \log n)$, позволяя обрабатывать большие объемы данных в реальном времени. Выбранный тип импликации и метод дефаззификации остаются неизменными между обучением и прогнозированием, обеспечивая консистентность вывода.

Проведение параллельных вычислений нечеткого вывода для множества окон временного ряда одновременно на GPU позволяет достичь значительного ускорения прогнозирования по сравнению с последовательной реализацией. Каждое окно обрабатывается независимо, что делает возможным эффективное распределение вычислений между нитями и блоками CUDA. Таким образом, разработанная двухэтапная процедура (обучение и прогнозирование) представляет собой целостную систему, в которой этап обучения готовит модель на основе исторических данных, а этап прогнозирования применяет эту модель к новым данным, используя согласованные параметры и алгоритмы.

\section{Выводы по главе}

\begin{enumerate}
	\item Предложенный параллельный алгоритм свертки НЗИ обеспечивает линейную зависимость сложности вычислений $O(D_{ftv}\cdot\log n)$ от размера расчетной сетки $D_{ftv}$ и линейную сложность по памяти $O(n)$ от числа выходов $n$.
	\item Адаптированный алгоритм метода роя частиц (PSO) позволяет организовать построение базы правил на основе набора обучающих данных за счет подбора оптимальных значений параметров ф. п. нечетких множеств. 
	\item Для вычисления дефаззификации по среднему максимуму адаптирован алгоритм метод роя частиц, учитывающий информацию о градиенте в точках оптимизируемой функции (Gradient-aware PSO). Учет градиента позволяет ускорить сходимость процедуры оптимизации.
	\item Верхнеуровневое описание процедур построения базы правил и предсказания прогноза состоит из этапов: составления набора окон запаздывания из временных рядов, применения адаптивной фаззификации, оптимизации базы правил или пакетного вычисления прогнозного значения для построенной базы правил.
\end{enumerate}

